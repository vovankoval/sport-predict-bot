from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
import asyncio
import requests

# –ö–ª—é—á–∏ ‚Äî —Ç–≤–æ–π –∫–ª—é—á —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!
API_TOKEN = '8075939198:AAEogNTrAsxOevk6Fanj04imVysNO23Ul5M'
GROQ_KEY = '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'  # –¢–≤–æ–π —Å–≤–µ–∂–∏–π –∫–ª—é—á

bot = Bot(token=API_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def start(message: types.Message):
    await message.reply("–ü—Ä–∏–≤–µ—Ç! üéâ –Ø –ò–ò-–±–æ—Ç –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ —Å–ø–æ—Ä—Ç.\n/predict ‚Äî —Å–≤–µ–∂–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ —Ñ—É—Ç–±–æ–ª (–∏ —Å–∫–æ—Ä–æ –∫–∏–±–µ—Ä—Å–ø–æ—Ä—Ç) –æ—Ç –º–æ—â–Ω–æ–≥–æ –ò–ò!")

@dp.message(Command("predict"))
async def predict(message: types.Message):
    await message.reply("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø—Ä–æ–≥–Ω–æ–∑—ã –æ—Ç –ò–ò... 10-20 —Å–µ–∫—É–Ω–¥.")

    prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç–∞–≤–∫–∞–º –Ω–∞ —Ñ—É—Ç–±–æ–ª —Å –æ—Ç–ª–∏—á–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π. –°–µ–≥–æ–¥–Ω—è 31 –¥–µ–∫–∞–±—Ä—è 2025 –≥–æ–¥–∞ ‚Äî –Ω–æ–≤–æ–≥–æ–¥–Ω—è—è –Ω–æ—á—å, –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–∞—Ç—á–µ–π –º–∞–ª–æ (–≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ç–æ–≤–∞—Ä–∏—â–µ—Å–∫–∏–µ –∏–ª–∏ –º–æ–ª–æ–¥—ë–∂–Ω—ã–µ).
–î–∞–π 5 —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ —Ñ—É—Ç–±–æ–ª—å–Ω—ã–µ –º–∞—Ç—á–∏ (–∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∏–∑ —Ç–æ–ø-–ª–∏–≥: –ê–ü–õ, –õ–∞ –õ–∏–≥–∞, –°–µ—Ä–∏—è A, –ë—É–Ω–¥–µ—Å–ª–∏–≥–∞ –∏ —Ç.–¥., –∏–ª–∏ –∫–ª—É–±–Ω—ã–µ —Ç–æ–≤–∞—Ä–∏—â–µ—Å–∫–∏–µ).
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ —É–∫–∞–∂–∏:
- –ú–∞—Ç—á (–∫–æ–º–∞–Ω–¥—ã)
- –ü—Ä–æ–≥–Ω–æ–∑ (–ø–æ–±–µ–¥–∞ –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã, –Ω–∏—á—å—è, —Ç–æ—á–Ω—ã–π —Å—á—ë—Ç –∏–ª–∏ —Ç–æ—Ç–∞–ª –≥–æ–ª–æ–≤)
- –ü—Ä–∏–º–µ—Ä–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π)
- –ö—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ (—Ç–µ–∫—É—â–∞—è —Ñ–æ—Ä–º–∞ –∫–æ–º–∞–Ω–¥, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–æ–ª–æ–≤, –∏—Å—Ç–æ—Ä–∏—è –≤—Å—Ç—Ä–µ—á, —Ç—Ä–∞–≤–º—ã –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã)
–°–¥–µ–ª–∞–π –ø—Ä–æ–≥–Ω–æ–∑—ã —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏, —Å –ø–ª—é—Å–∞–º–∏ –∏ –º–∏–Ω—É—Å–∞–º–∏, —á—Ç–æ–±—ã –±—ã–ª–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ."""

    groq_url = "https://api.groq.com/openai/v1/chat/completions"
    payload = {
        "model": "llama-3.3-70b-versatile",  # –ù–æ–≤–∞—è –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å 2025 –≥–æ–¥–∞!
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 800,
        "temperature": 0.8
    }
    headers_g = {"Authorization": f"Bearer {GROQ_KEY}", "Content-Type": "application/json"}
    
    try:
        response = requests.post(groq_url, json=payload, headers=headers_g, timeout=30)
        if response.status_code != 200:
            await message.reply(f"–û—à–∏–±–∫–∞ Groq: {response.status_code} {response.text}")
            return
        ai_resp = response.json()
        prediction = ai_resp['choices'][0]['message']['content']
    except Exception as e:
        await message.reply(f"–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏: {str(e)}")
        return

    await message.reply(f"ü§ñ –ü—Ä–æ–≥–Ω–æ–∑—ã –æ—Ç –ò–ò (Llama 3.3) –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ –º–∞—Ç—á–∏:\n\n{prediction}\n\n‚ö†Ô∏è –≠—Ç–æ —Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–µ! –°—Ç–∞–≤–∫–∏ ‚Äî –Ω–∞ —Å–≤–æ–π —Ä–∏—Å–∫, –Ω–∏—á–µ–≥–æ –Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—é.")

@dp.message()
async def echo(message: types.Message):
    await message.answer("–ù–∞–ø–∏—à–∏ /predict –¥–ª—è —Å–≤–µ–∂–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤!")

async def main():
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å Llama 3.3")
    await dp.start_polling(bot)

if __name__ == '__main__':
    asyncio.run(main())